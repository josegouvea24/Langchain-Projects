{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Encoder Re-Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 49 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 55 0 (offset 0)\n",
      "Ignoring wrong pointing object 57 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n",
      "Ignoring wrong pointing object 162 0 (offset 0)\n",
      "Ignoring wrong pointing object 229 0 (offset 0)\n",
      "Ignoring wrong pointing object 231 0 (offset 0)\n",
      "Ignoring wrong pointing object 252 0 (offset 0)\n",
      "Ignoring wrong pointing object 257 0 (offset 0)\n",
      "Ignoring wrong pointing object 294 0 (offset 0)\n",
      "Ignoring wrong pointing object 299 0 (offset 0)\n",
      "Ignoring wrong pointing object 319 0 (offset 0)\n",
      "Ignoring wrong pointing object 331 0 (offset 0)\n",
      "Ignoring wrong pointing object 336 0 (offset 0)\n",
      "Ignoring wrong pointing object 338 0 (offset 0)\n",
      "Ignoring wrong pointing object 340 0 (offset 0)\n",
      "Ignoring wrong pointing object 345 0 (offset 0)\n",
      "Ignoring wrong pointing object 347 0 (offset 0)\n",
      "Ignoring wrong pointing object 349 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# Create document chunks for embedding\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# Read the PDF file\n",
    "reader = PdfReader(\"microsoft_annual_report_2022.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "\n",
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "# Further split the chunks to prepare for embedding\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup chroma\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"microsoft_annual_report_2022\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "# Add documents to the vectorbase\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-ranking the long tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research and development $ 24, 512 $ 20, 716 18 % as a percent of revenue 12 % 12 % 0ppt research and development expenses include payroll, employee benefits, stock - based compensation expense, and other headcount - related expenses associated with product development. research and development expenses also include third - party development and programming costs, localization costs incurred to translate software for international markets, and the amortization of purchased software code and services content. research and development expenses increased $ 3. 8 billion or 18 % driven by investments in cloud engineering, gaming, and linkedin. sales and marketing ( in millions, except percentages ) 2022 2021 percentage change\n",
      "\n",
      ". investing in the future our success is based on our ability to create new and compelling products, services, and experiences for our users, to initiate and embrace disruptive technology trends, to enter new geographic and product markets, and to drive broad adoption of our products and services. we invest in a range of emerging technology trends and breakthroughs that we believe offer significant opportunities to deliver value to our customers and growth for the company. based on our assessment of key technology trends, we maintain our long - term commitment to research and development across a wide spectrum of technologies, tools, and platforms spanning digital work and life experiences, cloud computing, ai, devices, and operating systems. while our main product research and development facilities are located in redmond, washington, we also operate research and development facilities in other parts of the u. s. and around the world\n",
      "\n",
      ". this global approach helps us remain competitive in local markets and enables us to continue to attract top talent from across the world. we plan to continue to make significant investments in a broad range of product research and development activities, and as appropriate we will coordinate our research and development across operating segments and leverage the results across the company. in addition to our main research and development operations, we also operate microsoft research. microsoft research is one of the world ’ s largest corporate research organizations and works in close collaboration with top universities around the world to advance the state - of - the - art in computer science and a broad range of other disciplines, providing us a unique perspective on future trends and contributing to our innovation.\n",
      "\n",
      ". our responsibility as a corporation, our purpose and actions must be aligned with addressing the world ’ s problems, not creating new ones. at our very core, we need to deliver innovation that helps drive broad economic growth. we, as a company, will do well when the world around us does well. that ’ s what i believe will lead to widespread human progress and ultimately improve the lives of everyone. there is no more powerful input than digital technology to drive the world ’ s economic output. this is the core thesis for our being as a company, but it ’ s not enough. as we drive global economic growth, we must also commit to creating a more inclusive, equitable, sustainable, and trusted future. support inclusive economic growth we must ensure the growth we drive reaches every person, organization, community, and country. this starts with increasing access to digital skills\n",
      "\n",
      "61 note 4 — investments investment components the components of investments were as follows : ( in millions ) fair value level adjusted cost basis unrealized gains unrealized losses recorded basis cash and cash equivalents short - term investments equity investments june 30, 2022 changes in fair value recorded in other comprehensive income\n",
      "\n",
      ". we also increased the number of identified partners in the black partner growth initiative and continue to invest in the partner community through the black channel partner alliance by supporting events focused on business growth, accelerators, and mentorship. progress does not undo the egregious injustices of the past or diminish those who continue to live with inequity. we are committed to leveraging our resources to help accelerate diversity and inclusion across our ecosystem and to hold ourselves accountable to accelerate change – for microsoft, and beyond. investing in digital skills the covid - 19 pandemic led to record unemployment, disrupting livelihoods of people around the world. after helping over 30 million people in 249 countries and territories with our global skills initiative, we introduced a new initiative to support a more skills - based labor market, with greater flexibility and accessible learning paths to develop the right skills needed for the most in - demand jobs\n",
      "\n",
      ". for software warranties, we estimate the costs to provide bug fixes, such as security patches, over the estimated life of the software. we regularly reevaluate our estimates to assess the adequacy of the recorded warranty liabilities and adjust the amounts as necessary. research and development research and development expenses include payroll, employee benefits, stock - based compensation expense, and other headcount - related expenses associated with product development. research and development expenses also include third - party development and programming costs, localization costs incurred to translate software for international markets, and the amortization of purchased software code and services content. such costs related to software development are included in research and development expense until the point that technological feasibility is reached, which for our software products, is generally shortly before the products are released to production\n",
      "\n",
      ". cash used in investing increased $ 2. 7 billion to $ 30. 3 billion for fiscal year 2022, mainly due to a $ 13. 1 billion increase in cash used for acquisitions of companies, net of cash acquired, and purchases of intangible and other assets, and a $ 3. 3 billion increase in additions to property and equipment, offset in part by a $ 15. 6 billion increase in cash from net investment purchases, sales, and maturities.\n",
      "\n",
      ". fiscal year 2021 was a year of both successes and challenges. while we continued to make progress on several of our goals, with an overall reduction in our combined scope 1 and scope 2 emissions, our scope 3 emissions increased, due in substantial part to significant global datacenter expansions and growth in xbox sales and usage as a result of the covid - 19 pandemic. despite these scope 3 increases, we will continue to build the foundations and do the work to deliver on our commitments, and help our customers and partners achieve theirs. we have learned the impact of our work will not all be felt immediately, and our experience highlights how progress won ’ t always be linear. while fiscal year 2021 presented us with some new learnings, we also made some great progress. a few examples that illuminate the diversity of our work include : • we purchased the removal of 1. 4 million metrics tons of carbon. • four of our datacenters received new or renewed zero waste certifications\n",
      "\n",
      "liquidity and capital resources we expect existing cash, cash equivalents, short - term investments, cash flows from operations, and access to capital markets to continue to be sufficient to fund our operating activities and cash commitments for investing and financing activities, such as dividends, share repurchases, debt maturities, material capital expenditures, and the transition tax related to the tcja, for at least the next 12 months and thereafter for the foreseeable future. cash, cash equivalents, and investments cash, cash equivalents, and short - term investments totaled $ 104. 8 billion and $ 130. 3 billion as of june 30, 2022 and 2021, respectively. equity investments were $ 6. 9 billion and $ 6. 0 billion as of june 30, 2022 and 2021, respectively. our short - term investments are primarily intended to facilitate liquidity and capital preservation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the collection, retrieving more documents than usual\n",
    "query = \"What has been the investment in research and development?\"\n",
    "results = chroma_collection.query(query_texts=query, n_results=10, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in results['documents'][0]:\n",
    "    print(document)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f086d13b5584091bc1deb9dfc2d133e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b0e1055cfd4e0eb266e8b762982589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d451cfbf8641cbb1ff972eaf897e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7202f1e9bae642ccb258ad481c28fb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3b4581ba0441fc9c85c0d9e22a57f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "1.883019\n",
      "2.797129\n",
      "2.9828472\n",
      "-10.712097\n",
      "-8.425993\n",
      "-7.959864\n",
      "-3.3212464\n",
      "-9.8535\n",
      "-10.928937\n",
      "-8.527864\n"
     ]
    }
   ],
   "source": [
    "# Create query, doc pairs for each document\n",
    "pairs = [[query, doc] for doc in retrieved_documents]\n",
    "scores = cross_encoder.predict(pairs)\n",
    "print(\"Scores:\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Ordering:\n",
      "3\n",
      "2\n",
      "1\n",
      "7\n",
      "6\n",
      "5\n",
      "10\n",
      "8\n",
      "4\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Reorder the documents according to the scores\n",
    "print(\"New Ordering:\")\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-ranking with Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"What were the most important factors that contributed to increases in revenue?\"\n",
    "generated_queries = [\n",
    "    \"What were the major drivers of revenue growth?\",\n",
    "    \"Were there any new product launches that contributed to the increase in revenue?\",\n",
    "    \"Did any changes in pricing or promotions impact the revenue growth?\",\n",
    "    \"What were the key market trends that facilitated the increase in revenue?\",\n",
    "    \"Did any acquisitions or partnerships contribute to the revenue growth?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the original query with the generated queries, collect a bigger pool of documents\n",
    "queries = [original_query] + generated_queries\n",
    "\n",
    "results = chroma_collection.query(query_texts=queries, n_results=10, include=['documents', 'embeddings'])\n",
    "retrieved_documents = results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate the retrieved documents\n",
    "unique_documents = set()\n",
    "for documents in retrieved_documents:\n",
    "    for document in documents:\n",
    "        unique_documents.add(document)\n",
    "\n",
    "unique_documents = list(unique_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the query, doc pairs for each extracted document\n",
    "pairs = []\n",
    "for doc in unique_documents:\n",
    "    pairs.append([original_query, doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the pairs through the cross-encoder\n",
    "scores = cross_encoder.predict(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "-5.6333246\n",
      "-9.8078785\n",
      "-1.1550931\n",
      "-7.782469\n",
      "-4.9443893\n",
      "-7.900524\n",
      "-3.9324174\n",
      "-4.0156407\n",
      "-8.623781\n",
      "-9.5967045\n",
      "-4.457102\n",
      "-7.23612\n",
      "-4.623309\n",
      "-10.021421\n",
      "-11.156834\n",
      "-5.3622727\n",
      "-4.7538257\n",
      "-10.119462\n",
      "-7.1127553\n",
      "-10.171878\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores:\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Ordering:\n",
      "2\n",
      "6\n",
      "7\n",
      "10\n",
      "12\n",
      "16\n",
      "4\n",
      "15\n",
      "0\n",
      "18\n",
      "11\n",
      "3\n",
      "5\n",
      "8\n",
      "9\n",
      "1\n",
      "13\n",
      "17\n",
      "19\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# Observe how documents who were considered less relevant in the original embedding \n",
    "# similarity retrieval now score higher in their relevance to the original query\n",
    "print(\"New Ordering:\")\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
